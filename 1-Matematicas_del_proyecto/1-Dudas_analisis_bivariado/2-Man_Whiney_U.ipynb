{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b31ce37",
   "metadata": {},
   "source": [
    "# Explicación de la Prueba U de Mann-Whitney\n",
    "\n",
    "La **Prueba U de Mann-Whitney** (también conocida como prueba de suma de rangos de Mann-Whitney o prueba de Wilcoxon-Mann-Whitney) es una prueba estadística no paramétrica utilizada para comparar las distribuciones de dos grupos independientes. Es la alternativa no paramétrica a la prueba t de Student para muestras independientes, y se emplea cuando los datos no cumplen los supuestos de normalidad o cuando son de naturaleza ordinal.\n",
    "\n",
    "## Propósito\n",
    "\n",
    "El propósito principal de la Prueba U de Mann-Whitney es determinar si hay una diferencia estadísticamente significativa en la tendencia central (por ejemplo, la mediana) o en la distribución general de una variable entre dos grupos independientes. No asume una distribución normal de los datos, lo que la hace robusta para datos asimétricos o con valores atípicos.\n",
    "\n",
    "## Hipótesis\n",
    "\n",
    "Las hipótesis para la Prueba U de Mann-Whitney son:\n",
    "\n",
    "* **Hipótesis Nula ( $H_0$ ):** Las distribuciones de los dos grupos son idénticas (o que la mediana de la población de un grupo es igual a la mediana de la población del otro grupo).\n",
    "* **Hipótesis Alternativa ( $H_1$ ):** Las distribuciones de los dos grupos son diferentes (o que la mediana de la población de un grupo es diferente de la mediana de la población del otro grupo).\n",
    "    * También se pueden plantear hipótesis direccionales (unilaterales):\n",
    "        * $H_1$: La distribución de un grupo es estocásticamente mayor que la del otro.\n",
    "\n",
    "## Cómo Funciona (Principio General)\n",
    "\n",
    "La prueba funciona asignando rangos a todas las observaciones de ambos grupos combinados. Luego, suma los rangos para cada grupo por separado. Si los dos grupos provienen de la misma población, se esperaría que las sumas de rangos sean similares. Una gran diferencia en las sumas de rangos sugiere que las distribuciones son diferentes.\n",
    "\n",
    "## Estadístico de Prueba ( $U$ )\n",
    "\n",
    "El estadístico U se calcula para cada uno de los dos grupos. La fórmula para $U$ es la siguiente:\n",
    "\n",
    "Para el Grupo 1:\n",
    "$$ U_1 = R_1 - \\frac{n_1(n_1+1)}{2} $$\n",
    "\n",
    "Para el Grupo 2:\n",
    "$$ U_2 = R_2 - \\frac{n_2(n_2+1)}{2} $$\n",
    "\n",
    "Donde:\n",
    "\n",
    "* $R_1$ : Suma de los rangos de las observaciones del Grupo 1.\n",
    "* $R_2$ : Suma de los rangos de las observaciones del Grupo 2.\n",
    "* $n_1$ : Tamaño de la muestra del Grupo 1.\n",
    "* $n_2$ : Tamaño de la muestra del Grupo 2.\n",
    "\n",
    "El estadístico de prueba $U$ que se utiliza para la comparación final es el menor de $U_1$ y $U_2$. Alternativamente, se puede utilizar la suma de rangos (estadístico $W$ de Wilcoxon), que es equivalente.\n",
    "\n",
    "Existe una relación entre $U_1$ y $U_2$:\n",
    "$$ U_1 + U_2 = n_1 n_2 $$\n",
    "\n",
    "## Interpretación\n",
    "\n",
    "Una vez calculado el estadístico U, se compara con un valor crítico de una tabla de Mann-Whitney o, para muestras grandes, se aproxima a una distribución normal estándar para calcular un valor $Z$ y un p-valor.\n",
    "\n",
    "* **Si el p-valor < $\\alpha$ (nivel de significancia, e.g., 0.05):** Se rechaza la hipótesis nula. Esto indica que hay una diferencia estadísticamente significativa entre las distribuciones de los dos grupos.\n",
    "* **Si el p-valor $\\ge \\alpha$:** No se rechaza la hipótesis nula. Esto indica que no hay suficiente evidencia para afirmar que las distribuciones de los dos grupos son significativamente diferentes.\n",
    "\n",
    "## Supuestos\n",
    "\n",
    "A diferencia de la prueba t de Student, la Prueba U de Mann-Whitney tiene supuestos menos restrictivos:\n",
    "\n",
    "1.  **Independencia de las Observaciones:** Las observaciones dentro de cada grupo y entre los grupos deben ser independientes.\n",
    "2.  **Escala de Medición:** La variable dependiente debe ser al menos de escala ordinal.\n",
    "3.  **Muestras Aleatorias:** Las muestras deben ser seleccionadas aleatoriamente de sus respectivas poblaciones.\n",
    "4.  **Forma Similar de Distribución (para comparar medianas):** Si el objetivo es comparar específicamente las medianas, se asume que las formas de las distribuciones de los dos grupos son similares (aunque no necesariamente normales). Si las formas son muy diferentes, la prueba sigue siendo válida para comparar las distribuciones generales, pero la interpretación en términos de medianas puede ser menos precisa.\n",
    "\n",
    "## Cuándo usar la Prueba U de Mann-Whitney\n",
    "\n",
    "* Cuando se tienen **dos grupos independientes** y se desea comparar una variable dependiente.\n",
    "* Cuando la **variable dependiente es ordinal** (por ejemplo, escalas Likert, rangos).\n",
    "* Cuando la **variable dependiente es cuantitativa pero no cumple con el supuesto de normalidad** requerido para una prueba paramétrica (como la prueba t de Student) y/o hay presencia de valores atípicos que afectan la media.\n",
    "* Cuando los tamaños de muestra son pequeños y la normalidad no puede asumirse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d04ec",
   "metadata": {},
   "source": [
    "# Tabla Resumen: Prueba U de Mann-Whitney\n",
    "\n",
    "| Característica         | Prueba U de Mann-Whitney                                                |\n",
    "| :--------------------- | :---------------------------------------------------------------------- |\n",
    "| **Propósito Principal** | Comparar las **distribuciones** o **tendencias centrales (medianas)** de una variable continua u ordinal entre **dos grupos independientes**. |\n",
    "| **Tipo de Prueba** | No paramétrica (inferencial). Alternativa a la prueba t de Student para muestras independientes. |\n",
    "| **Hipótesis** | **$H_0$:** Las distribuciones (o medianas) de los dos grupos son idénticas. <br> **$H_1$:** Las distribuciones (o medianas) de los dos grupos son diferentes. (Puede ser unilateral). |\n",
    "| **Fórmula del Estadístico U** | Para el Grupo 1: $$ U_1 = R_1 - \\frac{n_1(n_1+1)}{2} $$ <br> Para el Grupo 2: $$ U_2 = R_2 - \\frac{n_2(n_2+1)}{2} $$ <br> Se usa el menor valor de $U_1$ y $U_2$ como estadístico de prueba. |\n",
    "| **Variables Requeridas** | 1. **Variable Dependiente:** Cuantitativa (intervalo/razón) u ordinal. <br> 2. **Variable Independiente:** Categórica con exactamente dos grupos (dicotómica). |\n",
    "| **Supuestos Clave** | 1. **Independencia:** Las observaciones son independientes. <br> 2. **Escala de Medición:** Variable dependiente es al menos ordinal. <br> 3. **Muestras Aleatorias:** Las muestras provienen de poblaciones de forma similar (para inferencias sobre medianas). |\n",
    "| **Interpretación** | Se calcula un p-valor. <br> **P-valor < $\\alpha$:** Rechazar $H_0$, hay una diferencia significativa en las distribuciones/medianas. <br> **P-valor $\\ge \\alpha$:** No rechazar $H_0$, no hay evidencia suficiente de una diferencia significativa. |\n",
    "| **Ventajas** | No requiere que los datos sigan una distribución normal. <br> Robusta a valores atípicos. <br> Adecuada para datos ordinales. |\n",
    "| **Desventajas** | Menor potencia estadística que la prueba t si los datos cumplen los supuestos de normalidad. <br> Interpreta diferencias en medianas solo si las formas de las distribuciones son similares. |\n",
    "| **Uso Típico** | Comparar la eficacia de dos tratamientos, diferencias en puntuaciones de encuestas entre dos grupos, etc., cuando los datos no son normales. |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
